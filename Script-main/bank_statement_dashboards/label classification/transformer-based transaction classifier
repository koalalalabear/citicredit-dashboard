# Transformer-Based Transaction Classifier with Class Weights

# Load and Explore the Data
import pandas as pd
import matplotlib.pyplot as plt

# Replace with your actual data file
df = pd.read_csv("transactions.csv")
print(df.head())

# Visualize class distribution
df['category'].value_counts(normalize=True).plot.pie(autopct='%.1f%%')
plt.title("Class Distribution")
plt.ylabel("")
plt.show()

# Preprocess Labels and Tokenize Text
from sklearn.preprocessing import LabelEncoder
from transformers import AutoTokenizer

label_encoder = LabelEncoder()
df['label'] = label_encoder.fit_transform(df['category'])

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# ‚öñÔ∏è Step 4: Compute Class Weights
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
import torch

class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(df['label']), y=df['label'])
class_weights = torch.tensor(class_weights, dtype=torch.float)

#Prepare Dataset for Transformers
from datasets import Dataset

dataset = Dataset.from_pandas(df[['transaction_description', 'label']])

def tokenize(batch):
    return tokenizer(batch['transaction_description'], padding='max_length', truncation=True)

dataset = dataset.map(tokenize, batched=True)
dataset = dataset.train_test_split(test_size=0.2)

#Define Model and Custom Trainer with Class Weights
from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer
import torch.nn as nn

model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=len(label_encoder.classes_))

class WeightedTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        labels = inputs.pop("labels")
        outputs = model(**inputs)
        logits = outputs.logits
        loss_fn = nn.CrossEntropyLoss(weight=class_weights)
        loss = loss_fn(logits, labels)
        return (loss, outputs) if return_outputs else loss

#Training Arguments and Model Training
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    logging_dir="./logs",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
)

trainer = WeightedTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset['train'],
    eval_dataset=dataset['test'],
    tokenizer=tokenizer,
)

trainer.train()

# üìà Step 8: Evaluate the Model
from sklearn.metrics import classification_report

preds = trainer.predict(dataset['test'])
pred_labels = preds.predictions.argmax(axis=1)

print(classification_report(dataset['test']['label'], pred_labels, target_names=label_encoder.classes_))
